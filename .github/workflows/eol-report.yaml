name: EOL Dependencies Check

on:
  pull_request: 
    types: [opened, synchronize, reopened, closed]
  workflow_dispatch:
    inputs:
      fail_on_eol:
        description: 'Fail the workflow if EOL dependencies are found'
        required: false
        default: false
        type: boolean
      days_threshold:
        description: 'Alert threshold in days before EOL'
        required: false
        default: '90'
        type: string

env:
  MAVEN_OPTS: -Dhttp.keepAlive=false -Dmaven.wagon.http.pool=false

jobs:
  eol-check:
    runs-on: ubuntu-latest
    name: Check Dependencies EOL Status
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up JDK 17
      uses: actions/setup-java@v4
      with:
        java-version: '17'
        distribution: zulu
        cache: maven
        
    - name: Extract Maven dependencies
      run: |
          python3 << 'EOF'
          import xml.etree.ElementTree as ET
          import os
          import json
          from pathlib import Path
          import re
          
          def extract_maven_deps():
              dependencies = {}
              all_properties = {}  # Global properties from parent
              
              # First pass: collect all properties from all POMs
              for pom_file in Path('.').rglob('pom.xml'):
                  try:
                      print(f"Loading properties from POM: {pom_file}")
                      tree = ET.parse(pom_file)
                      root = tree.getroot()
                      
                      # Handle namespaces properly
                      ns = {}
                      if root.tag.startswith('{'):
                          ns_uri = root.tag.split('}')[0][1:]
                          ns = {'m': ns_uri}
                      
                      # Extract properties from this POM
                      if ns:
                          properties_elem = root.find('.//m:properties', ns)
                      else:
                          properties_elem = root.find('.//properties')
                      
                      if properties_elem is not None:
                          pom_props = 0
                          for prop in properties_elem:
                              prop_name = prop.tag
                              if '}' in prop_name:
                                  prop_name = prop_name.split('}')[1]
                              if prop.text:
                                  all_properties[prop_name] = prop.text.strip()
                                  pom_props += 1
                          print(f"  Found {pom_props} properties in this POM")
                                  
                  except Exception as e:
                      print(f"Error reading POM {pom_file}: {e}")
                      continue
              
              print(f"Collected {len(all_properties)} total properties from all POMs")
              
              # Second pass: process all POMs
              for pom_file in Path('.').rglob('pom.xml'):
                  try:
                      print(f"Processing {pom_file}")
                      tree = ET.parse(pom_file)
                      root = tree.getroot()
                      
                      # Handle namespaces properly
                      ns = {}
                      if root.tag.startswith('{'):
                          ns_uri = root.tag.split('}')[0][1:]
                          ns = {'m': ns_uri}
                      
                      def find_direct_child(parent, tag_name):
                          """Find direct child element (not descendants)"""
                          for child in parent:
                              child_tag = child.tag
                              if '}' in child_tag:
                                  child_tag = child_tag.split('}')[1]
                              if child_tag == tag_name:
                                  return child
                          return None
                      
                      def get_text_safe(elem):
                          return elem.text.strip() if elem is not None and elem.text else None
                      
                      def resolve_version(version_str):
                          if not version_str:
                              return None
                          if version_str.startswith('${') and version_str.endswith('}'):
                              prop_name = version_str[2:-1]
                              resolved = all_properties.get(prop_name)
                              if resolved:
                                  return resolved
                              else:
                                  print(f"  Warning: Could not resolve property {prop_name}")
                                  return version_str
                          return version_str
                      
                      # Extract dependencies from both <dependencies> and <dependencyManagement><dependencies>
                      deps_elements = []
                      
                      # Look for regular dependencies
                      if ns:
                          deps_sections = root.findall('.//m:dependencies', ns)
                      else:
                          deps_sections = root.findall('.//dependencies')
                      
                      for deps_section in deps_sections:
                          for child in deps_section:
                              child_tag = child.tag
                              if '}' in child_tag:
                                  child_tag = child_tag.split('}')[1]
                              if child_tag == 'dependency':
                                  deps_elements.append(child)
                      
                      print(f"  Found {len(deps_elements)} dependency elements")
                      
                      for dep in deps_elements:
                          group_id_elem = find_direct_child(dep, 'groupId')
                          artifact_id_elem = find_direct_child(dep, 'artifactId')
                          version_elem = find_direct_child(dep, 'version')
                          scope_elem = find_direct_child(dep, 'scope')
                          type_elem = find_direct_child(dep, 'type')
                          
                          group_id = get_text_safe(group_id_elem)
                          artifact_id = get_text_safe(artifact_id_elem)
                          version = get_text_safe(version_elem)
                          scope = get_text_safe(scope_elem)
                          dep_type = get_text_safe(type_elem)
                          
                          if not group_id or not artifact_id:
                              continue
                          
                          # Skip test and provided scope dependencies
                          if scope and scope.lower() in ['test', 'provided']:
                              continue
                          
                          # Skip BOM dependencies (type=pom with import scope)
                          if dep_type == 'pom' and scope == 'import':
                              continue
                          
                          # Resolve version
                          version = resolve_version(version)
                          
                          # Only include dependencies with resolved versions
                          if version and not version.startswith('${'):
                              key = f"{group_id}:{artifact_id}"
                              dependencies[key] = {
                                  'groupId': group_id,
                                  'artifactId': artifact_id,
                                  'version': version,
                                  'type': 'dependency',
                                  'scope': scope or 'compile'
                              }
                              print(f"  Added: {key} = {version}")
                          elif version:
                              print(f"  Skipped (unresolved version): {group_id}:{artifact_id} = {version}")
                              
                  except Exception as e:
                      print(f"Error parsing {pom_file}: {e}")
                      continue
              
              return dependencies
          
          # Extract dependencies
          deps = extract_maven_deps()
          
          # Map to EOL products
          eol_mappings = {
              'org.springframework.boot': 'spring-boot',
              'org.springframework': 'spring-framework',
              'org.springframework.cloud': 'spring-cloud',
              'com.fasterxml.jackson.core': 'jackson',
              'com.fasterxml.jackson': 'jackson',
              'org.postgresql': 'postgresql',
              'redis.clients': 'redis',
              'org.mongodb': 'mongodb',
              'io.swagger.core.v3': 'openapi',
              'io.swagger.v3': 'openapi',
              'org.springdoc': 'openapi',
              'org.apache.tomcat': 'tomcat',
              'org.apache.tomcat.embed': 'tomcat',
              'org.eclipse.jetty': 'jetty',
              'junit': 'junit',
              'org.junit': 'junit',
              'org.mockito': 'mockito',
              'ch.qos.logback': 'logback',
              'org.slf4j': 'slf4j',
              'org.hibernate': 'hibernate'
          }
          
          eol_deps = {}
          for dep_key, dep_info in deps.items():
              group_id = dep_info['groupId']
              for group_prefix, eol_product in eol_mappings.items():
                  if group_id.startswith(group_prefix):
                      eol_deps[eol_product] = {
                          'version': dep_info['version'],
                          'dependency': dep_key
                      }
                      break
          
          # Use Maven to get dependency list which includes resolved versions
          print(f"Found {len(deps)} dependencies with explicit versions")
          print("\nUsing Maven to get effective dependency list...")
          try:
              import subprocess
              
              # Get dependency list for the api-gateway module (has most dependencies)
              result = subprocess.run(['mvn', 'dependency:list'], 
                                    capture_output=True, text=True, cwd='api-gateway')
              
              if result.returncode == 0:
                  maven_deps = 0
                  # Parse Maven output
                  for line in result.stdout.splitlines():
                      line = line.strip()
                      if line.startswith('[INFO]    ') and ':' in line and 'jar:' in line:
                          # Extract dependency info from Maven output
                          # Format: [INFO]    groupId:artifactId:type:version:scope -- module info
                          parts = line.replace('[INFO]    ', '').strip()
                          
                          # Split by '--' to get just the dependency part
                          if '--' in parts:
                              parts = parts.split('--')[0].strip()
                          
                          if parts.count(':') >= 4:
                              try:
                                  dep_parts = parts.split(':')
                                  group_id = dep_parts[0].strip()
                                  artifact_id = dep_parts[1].strip()
                                  packaging = dep_parts[2].strip()
                                  version = dep_parts[3].strip()
                                  scope = dep_parts[4].strip() if len(dep_parts) > 4 else 'compile'
                                  
                                  # Skip test dependencies
                                  if scope.lower() in ['test', 'provided']:
                                      continue
                                  
                                  key = f"{group_id}:{artifact_id}"
                                  if key not in deps:  # Don't override XML parsed ones
                                      deps[key] = {
                                          'groupId': group_id,
                                          'artifactId': artifact_id,
                                          'version': version,
                                          'type': 'dependency',
                                          'scope': scope
                                      }
                                      maven_deps += 1
                              except Exception as e:
                                  print(f"Error parsing Maven output line: {line} - {e}")
                                  continue
                  
                  print(f"Maven resolved {maven_deps} additional dependencies")
                  
              else:
                  print(f"Maven dependency:list failed: {result.stderr}")
              
          except Exception as e:
              print(f"Maven resolution failed: {e}")
          
          # Re-map dependencies to EOL products with complete dependency list
          eol_deps = {}
          for dep_key, dep_info in deps.items():
              group_id = dep_info['groupId']
              for group_prefix, eol_product in eol_mappings.items():
                  if group_id.startswith(group_prefix):
                      eol_deps[eol_product] = {
                          'version': dep_info['version'],
                          'dependency': dep_key
                      }
                      break
          
          print(f"\nFound {len(deps)} total dependencies")
          print(f"Mapped {len(eol_deps)} dependencies to EOL products")
          
          # Save results (even if empty)
          with open('eol_dependencies.json', 'w') as f:
              json.dump(eol_deps, f, indent=2)
          
          if not eol_deps:
              print("No dependencies mapped to EOL products")
          else:
              print("EOL-trackable dependencies:")
              for eol_product, info in eol_deps.items():
                  print(f"  {eol_product}: {info['version']} (from {info['dependency']})")
          EOF
          
    - name: Check EOL status for dependencies
      id: eol-check
      run: |
        echo "Checking EOL status using endoflife.date API..."
        
        # Set threshold days (default 90 days)
        THRESHOLD_DAYS="${{ github.event.inputs.days_threshold || '90' }}"
        
        cat > check_eol.py << 'EOF'
        import json
        import requests
        import sys
        from datetime import datetime, timedelta
        import os
        
        def check_eol_status():
            threshold_days = int(os.getenv('THRESHOLD_DAYS', '90'))
            today = datetime.now()
            threshold_date = today + timedelta(days=threshold_days)
            
            with open('eol_dependencies.json', 'r') as f:
                dependencies = json.load(f)
            
            results = {
                'eol': [],
                'approaching_eol': [],
                'supported': [],
                'unknown': []
            }
            
            for product, info in dependencies.items():
                try:
                    print(f"Checking {product}...")
                    
                    # Get product info from endoflife.date API
                    response = requests.get(f'https://endoflife.date/api/{product}.json', timeout=10)
                    
                    if response.status_code != 200:
                        print(f"  Product {product} not found in EOL database")
                        results['unknown'].append({
                            'product': product,
                            'version': info['version'],
                            'dependency': info['dependency'],
                            'reason': 'Product not found in EOL database'
                        })
                        continue
                    
                    cycles = response.json()
                    current_version = info['version']
                    
                    # Find matching version or closest version
                    matching_cycle = None
                    for cycle in cycles:
                        cycle_version = str(cycle.get('cycle', ''))
                        
                        # Direct match
                        if current_version.startswith(cycle_version):
                            matching_cycle = cycle
                            break
                        
                        # Semantic version match (e.g., 2.7.x matches 2.7)
                        if current_version.split('.')[0] == cycle_version.split('.')[0]:
                            if len(cycle_version.split('.')) >= 2 and len(current_version.split('.')) >= 2:
                                if current_version.split('.')[1] == cycle_version.split('.')[1]:
                                    matching_cycle = cycle
                                    break
                    
                    if not matching_cycle:
                        # Use the first (latest) cycle as fallback
                        matching_cycle = cycles[0] if cycles else None
                    
                    if not matching_cycle:
                        results['unknown'].append({
                            'product': product,
                            'version': current_version,
                            'dependency': info['dependency'],
                            'reason': 'No matching version cycle found'
                        })
                        continue
                    
                    eol_date = matching_cycle.get('eol')
                    support_date = matching_cycle.get('support')
                    lts = matching_cycle.get('lts', False)
                    
                    # Parse EOL date
                    eol_datetime = None
                    if eol_date and eol_date != True and eol_date != False:
                        try:
                            eol_datetime = datetime.strptime(str(eol_date), '%Y-%m-%d')
                        except:
                            pass
                    
                    # Check status
                    status_info = {
                        'product': product,
                        'version': current_version,
                        'dependency': info['dependency'],
                        'cycle': matching_cycle.get('cycle'),
                        'eol_date': eol_date,
                        'support_date': support_date,
                        'lts': lts
                    }
                    
                    if eol_date == True:
                        results['eol'].append(status_info)
                        print(f"  ‚ùå {product} {current_version} is EOL")
                    elif eol_datetime and eol_datetime <= today:
                        results['eol'].append(status_info)
                        print(f"  ‚ùå {product} {current_version} is EOL (since {eol_date})")
                    elif eol_datetime and eol_datetime <= threshold_date:
                        status_info['days_until_eol'] = (eol_datetime - today).days
                        results['approaching_eol'].append(status_info)
                        print(f"  ‚ö†Ô∏è  {product} {current_version} approaching EOL ({eol_date})")
                    else:
                        results['supported'].append(status_info)
                        print(f"  ‚úÖ {product} {current_version} is supported")
                        
                except Exception as e:
                    print(f"  Error checking {product}: {e}")
                    results['unknown'].append({
                        'product': product,
                        'version': info['version'],
                        'dependency': info['dependency'],
                        'reason': f'Error: {str(e)}'
                    })
            
            return results
        
        # Run EOL check
        results = check_eol_status()
        
        # Save results
        with open('eol_results.json', 'w') as f:
            json.dump(results, f, indent=2)
        
        # Output summary
        total_checked = len(results['eol']) + len(results['approaching_eol']) + len(results['supported']) + len(results['unknown'])
        print(f"\nüìä EOL Check Summary:")
        print(f"Total dependencies checked: {total_checked}")
        print(f"‚ùå EOL: {len(results['eol'])}")
        print(f"‚ö†Ô∏è  Approaching EOL: {len(results['approaching_eol'])}")
        print(f"‚úÖ Supported: {len(results['supported'])}")
        print(f"‚ùì Unknown: {len(results['unknown'])}")
        
        # Set outputs for GitHub Actions
        eol_count = len(results['eol'])
        approaching_count = len(results['approaching_eol'])
        
        print(f"EOL_COUNT={eol_count}")
        print(f"APPROACHING_COUNT={approaching_count}")
        print(f"TOTAL_ISSUES={eol_count + approaching_count}")
        EOF
        
        # Check if we have dependencies to analyze
        if [ -f eol_dependencies.json ] && [ -s eol_dependencies.json ]; then
          # Set environment variable and run the Python script
          THRESHOLD_DAYS="$THRESHOLD_DAYS" python3 check_eol.py
          
          # Set GitHub environment variables from Python output
          EOL_COUNT=$(python3 -c "
          import json
          try:
              with open('eol_results.json', 'r') as f:
                  results = json.load(f)
              print(len(results['eol']))
          except:
              print('0')
          ")
          APPROACHING_COUNT=$(python3 -c "
          import json
          try:
              with open('eol_results.json', 'r') as f:
                  results = json.load(f)
              print(len(results['approaching_eol']))
          except:
              print('0')
          ")
        else
          echo "No dependencies found to check - creating empty results"
          EOL_COUNT=0
          APPROACHING_COUNT=0
          
          # Create empty results file
          cat > eol_results.json << 'EOLEOF'
          {
            "eol": [],
            "approaching_eol": [],
            "supported": [],
            "unknown": []
          }
          EOLEOF
        fi
        
        TOTAL_ISSUES=$((EOL_COUNT + APPROACHING_COUNT))
        
        echo "EOL_COUNT=$EOL_COUNT" >> $GITHUB_ENV
        echo "APPROACHING_COUNT=$APPROACHING_COUNT" >> $GITHUB_ENV
        echo "TOTAL_ISSUES=$TOTAL_ISSUES" >> $GITHUB_ENV
        
    - name: Generate EOL Report
      id: generate-report
      run: |
        echo "Generating detailed EOL report..."
        
        cat > generate_report.py << 'EOF'
        import json
        from datetime import datetime
        
        def generate_markdown_report():
            with open('eol_results.json', 'r') as f:
                results = json.load(f)
            
            report = []
            report.append("# üîç Dependencies End-of-Life Report")
            report.append(f"*Generated on {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}*")
            report.append("")
            
            # Summary
            total = len(results['eol']) + len(results['approaching_eol']) + len(results['supported']) + len(results['unknown'])
            report.append("## üìä Summary")
            report.append("| Status | Count | Description |")
            report.append("|--------|--------|-------------|")
            report.append(f"| ‚ùå EOL | {len(results['eol'])} | Dependencies that have reached end-of-life |")
            report.append(f"| ‚ö†Ô∏è Approaching EOL | {len(results['approaching_eol'])} | Dependencies approaching EOL within threshold |")
            report.append(f"| ‚úÖ Supported | {len(results['supported'])} | Dependencies with active support |")
            report.append(f"| ‚ùì Unknown | {len(results['unknown'])} | Dependencies not found in EOL database |")
            report.append(f"| **Total** | **{total}** | **All checked dependencies** |")
            report.append("")
            
            # EOL Dependencies
            if results['eol']:
                report.append("## ‚ùå End-of-Life Dependencies")
                report.append("These dependencies have reached their end-of-life and should be updated immediately:")
                report.append("")
                report.append("| Product | Version | Dependency | EOL Date | LTS |")
                report.append("|---------|---------|------------|----------|-----|")
                for dep in results['eol']:
                    lts_badge = "‚úÖ" if dep.get('lts') else "‚ùå"
                    eol_date = dep.get('eol_date', 'Unknown')
                    report.append(f"| {dep['product']} | {dep['version']} | `{dep['dependency']}` | {eol_date} | {lts_badge} |")
                report.append("")
            
            # Approaching EOL
            if results['approaching_eol']:
                report.append("## ‚ö†Ô∏è Dependencies Approaching EOL")
                report.append("These dependencies will reach end-of-life soon:")
                report.append("")
                report.append("| Product | Version | Dependency | EOL Date | Days Until EOL | LTS |")
                report.append("|---------|---------|------------|----------|----------------|-----|")
                for dep in results['approaching_eol']:
                    lts_badge = "‚úÖ" if dep.get('lts') else "‚ùå"
                    days_until = dep.get('days_until_eol', 'Unknown')
                    eol_date = dep.get('eol_date', 'Unknown')
                    report.append(f"| {dep['product']} | {dep['version']} | `{dep['dependency']}` | {eol_date} | {days_until} | {lts_badge} |")
                report.append("")
            
            # Supported Dependencies
            if results['supported']:
                report.append("## ‚úÖ Supported Dependencies")
                report.append("<details>")
                report.append("<summary>Click to expand supported dependencies</summary>")
                report.append("")
                report.append("| Product | Version | Dependency | EOL Date | LTS |")
                report.append("|---------|---------|------------|----------|-----|")
                for dep in results['supported']:
                    lts_badge = "‚úÖ" if dep.get('lts') else "‚ùå"
                    eol_date = dep.get('eol_date', 'Future')
                    report.append(f"| {dep['product']} | {dep['version']} | `{dep['dependency']}` | {eol_date} | {lts_badge} |")
                report.append("")
                report.append("</details>")
                report.append("")
            
            # Unknown Dependencies
            if results['unknown']:
                report.append("## ‚ùì Unknown Dependencies")
                report.append("These dependencies could not be checked against the EOL database:")
                report.append("")
                report.append("| Product | Version | Dependency | Reason |")
                report.append("|---------|---------|------------|--------|")
                for dep in results['unknown']:
                    reason = dep.get('reason', 'Unknown')
                    report.append(f"| {dep['product']} | {dep['version']} | `{dep['dependency']}` | {reason} |")
                report.append("")
            
            # Recommendations
            report.append("## üîß Recommendations")
            if results['eol']:
                report.append("### Immediate Action Required")
                report.append("- Update all EOL dependencies to supported versions")
                report.append("- Check for security vulnerabilities in EOL dependencies")
                report.append("- Plan migration timeline for breaking changes")
            
            if results['approaching_eol']:
                report.append("### Plan for Updates")
                report.append("- Schedule updates for dependencies approaching EOL")
                report.append("- Test compatibility with newer versions")
                report.append("- Monitor release schedules for dependency updates")
            
            report.append("")
            report.append("### Useful Resources")
            report.append("- [endoflife.date](https://endoflife.date/) - EOL information database")
            report.append("- [OWASP Dependency Check](https://owasp.org/www-project-dependency-check/) - Security vulnerability scanning")
            report.append("- [Renovate](https://renovatebot.com/) - Automated dependency updates")
            
            return "\n".join(report)
        
        # Generate report
        markdown_report = generate_markdown_report()
        
        # Save report
        with open('eol_report.md', 'w') as f:
            f.write(markdown_report)
        
        # Output to GitHub summary
        print("EOL_REPORT<<EOF" >> $GITHUB_OUTPUT)
        print(markdown_report >> $GITHUB_OUTPUT)
        print("EOF" >> $GITHUB_OUTPUT)
        
        print("Report generated successfully!")
        EOF
        
        python3 generate_report.py
        
    - name: Upload EOL Report
      uses: actions/upload-artifact@v4
      with:
        name: eol-report
        path: |
          eol_report.md
          eol_results.json
          eol_dependencies.json
        retention-days: 30
        
    - name: Comment on PR (if applicable)
      if: github.event_name == 'pull_request' && env.TOTAL_ISSUES > 0
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const report = fs.readFileSync('eol_report.md', 'utf8');
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: `## üîç EOL Dependencies Check Results\n\n${report}`
          });
          
    - name: Create Issue for EOL Dependencies
      if: env.EOL_COUNT > 0 && github.event_name == 'schedule'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const report = fs.readFileSync('eol_report.md', 'utf8');
          
          // Check if EOL issue already exists
          const issues = await github.rest.issues.listForRepo({
            owner: context.repo.owner,
            repo: context.repo.repo,
            labels: ['dependencies', 'eol'],
            state: 'open'
          });
          
          const title = `üîç End-of-Life Dependencies Detected (${process.env.EOL_COUNT} EOL, ${process.env.APPROACHING_COUNT} approaching)`;
          
          if (issues.data.length === 0) {
            // Create new issue
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: title,
              body: report,
              labels: ['dependencies', 'eol', 'security']
            });
          } else {
            // Update existing issue
            await github.rest.issues.update({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issues.data[0].number,
              title: title,
              body: report
            });
          }
          
    - name: Add to GitHub Summary
      run: |
        echo "## üîç EOL Dependencies Check Results" >> $GITHUB_STEP_SUMMARY
        cat eol_report.md >> $GITHUB_STEP_SUMMARY
        
    - name: Fail on EOL Dependencies
      if: github.event.inputs.fail_on_eol == 'true' && env.EOL_COUNT > 0
      run: |
        echo "‚ùå Failing workflow due to $EOL_COUNT EOL dependencies found"
        echo "Use the generated report to update these dependencies"
        exit 1
