name: EOL Dependencies Check

on:
  schedule: 
    - cron: '0 11 * * 1'  # Weekly on Mondays at 11:00 UTC
  pull_request: 
    types: [opened, synchronize, reopened, closed]
  workflow_dispatch:
    inputs:
      fail_on_eol:
        description: 'Fail the workflow if EOL dependencies are found'
        required: false
        default: false
        type: boolean
      days_threshold:
        description: 'Alert threshold in days before EOL'
        required: false
        default: '90'
        type: string

env:
  MAVEN_OPTS: -Dhttp.keepAlive=false -Dmaven.wagon.http.pool=false

jobs:
  eol-check:
    runs-on: ubuntu-latest
    name: Check Dependencies EOL Status
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up JDK 17
      uses: actions/setup-java@v4
      with:
        java-version: '17'
        distribution: zulu
        cache: maven
        
    - name: Build project
      run: |
        echo "Building multi-module project to resolve inter-module dependencies..."
        mvn clean install -Dmaven.test.skip=true
        
    - name: Extract project dependencies
      run: |
          python3 << 'EOF'
          import subprocess
          import json
          import re
          from datetime import datetime
          
          def extract_maven_dependencies():
              """Extract dependencies using Maven dependency:list command"""
              print("üîç Extracting dependencies using Maven...")
              
              dependencies = {}
              
              try:
                  # Try to resolve dependencies first to handle multi-module projects
                  print("  Pre-resolving dependencies for multi-module project...")
                  resolve_result = subprocess.run([
                      'mvn', 'dependency:resolve'
                  ], capture_output=True, text=True, cwd='.')
                  
                  if resolve_result.returncode != 0:
                      print(f"‚ö†Ô∏è  Maven dependency:resolve had issues: {resolve_result.stderr}")
                      # Continue anyway as this might still work
                  
                  # Get all dependencies using Maven dependency:list for all modules
                  # This includes all resolved transitive dependencies with actual versions
                  print("  Running Maven dependency:list for all modules...")
                  result = subprocess.run([
                      'mvn', 'dependency:list', '-DexcludeTransitive=false'
                  ], capture_output=True, text=True, cwd='.')
                  
                  if result.returncode != 0:
                      print(f"‚ùå Maven dependency:list failed:")
                      print(f"   Return code: {result.returncode}")
                      print(f"   stderr: {result.stderr}")
                      print(f"   stdout: {result.stdout}")
                      
                      # Try alternative approach: use dependency:tree instead
                      print("  Trying alternative approach with dependency:tree...")
                      tree_result = subprocess.run([
                          'mvn', 'dependency:tree', '-DoutputType=text'
                      ], capture_output=True, text=True, cwd='.')
                      
                      if tree_result.returncode == 0:
                          print("  ‚úÖ Using dependency:tree output as fallback")
                          result = tree_result
                      else:
                          print(f"‚ùå dependency:tree also failed: {tree_result.stderr}")
                          return dependencies
                  
                  print(f"‚úÖ Maven dependency:list completed successfully")
                  
                  # Extract module information from Maven output
                  modules_processed = []
                  for line in result.stdout.splitlines():
                      if 'Building ' in line and '[' in line and '/' in line:
                          # Extract module name from "Building module-name version [x/y]"
                          parts = line.split('Building')[1].strip().split('[')[0].strip()
                          module_name = parts.split()[0] if parts else 'unknown'
                          modules_processed.append(module_name)
                  
                  if modules_processed:
                      print(f"  üìã Modules processed: {', '.join(modules_processed)}")
                  
                  # Parse Maven output to extract dependency information
                  # Format: [INFO]    groupId:artifactId:type:version:scope -- module info
                  dependency_count = 0
                  
                  for line in result.stdout.splitlines():
                      line = line.strip()
                      
                      # Look for dependency lines from both dependency:list and dependency:tree
                      # dependency:list format: [INFO]    groupId:artifactId:type:version:scope -- module info
                      # dependency:tree format: [INFO] +- groupId:artifactId:type:version:scope
                      is_dependency_list = line.startswith('[INFO]    ') and ':' in line and not line.startswith('[INFO]    none')
                      is_dependency_tree = (line.startswith('[INFO] ') and 
                                           any(prefix in line for prefix in ['+- ', '\\- ', '|  ']) and 
                                           ':' in line)
                      
                      if is_dependency_list or is_dependency_tree:
                          # Parse based on format
                          if is_dependency_list:
                              # Remove the [INFO] prefix and any trailing module info
                              dependency_info = line.replace('[INFO]    ', '').strip()
                              # Split by '--' to get just the dependency part (before module info)
                              if '--' in dependency_info:
                                  dependency_info = dependency_info.split('--')[0].strip()
                          else:  # is_dependency_tree
                              # Remove [INFO] prefix and tree characters
                              dependency_info = line.replace('[INFO] ', '').strip()
                              # Remove tree prefixes like '+- ', '\\- ', '|  '
                              for prefix in ['+- ', '\\- ', '|  +- ', '|  \\- ', '   ']:
                                  if dependency_info.startswith(prefix):
                                      dependency_info = dependency_info[len(prefix):].strip()
                                      break
                          
                          # Parse dependency format: groupId:artifactId:type:version:scope
                          parts = dependency_info.split(':')
                          if len(parts) >= 4:  # At minimum we need groupId:artifactId:type:version
                              try:
                                  group_id = parts[0].strip()
                                  artifact_id = parts[1].strip()
                                  packaging = parts[2].strip() if len(parts) > 2 else 'jar'
                                  version = parts[3].strip() if len(parts) > 3 else 'unknown'
                                  scope = parts[4].strip() if len(parts) > 4 else 'compile'
                                  
                                  # Skip empty or malformed entries
                                  if not group_id or not artifact_id or group_id == 'none':
                                      continue
                                  
                                  # Only include compile and runtime dependencies (skip test, provided)
                                  if scope.lower() in ['test', 'provided']:
                                      continue
                                  
                                  # Create dependency key
                                  dep_key = f"{group_id}:{artifact_id}"
                                  
                                  # Store dependency information (avoid duplicates)
                                  if dep_key not in dependencies:
                                      dependencies[dep_key] = {
                                          'groupId': group_id,
                                          'artifactId': artifact_id,
                                          'version': version,
                                          'packaging': packaging,
                                          'scope': scope
                                      }
                                      dependency_count += 1
                                  
                              except (IndexError, ValueError) as e:
                                  print(f"‚ö†Ô∏è  Could not parse dependency line: {dependency_info} - {e}")
                                  continue
                  
                  print(f"üì¶ Found {dependency_count} dependencies from Maven")
                  
              except Exception as e:
                  print(f"‚ùå Error running Maven dependency command: {e}")
              
              return dependencies
          
          # Extract dependencies using Maven
          deps = extract_maven_dependencies()
          
          # Create dynamic EOL mappings based on actual dependencies found
          def create_dynamic_eol_mappings(dependencies):
              """
              Dynamically create EOL product mappings based on the actual dependencies found.
              This analyzes dependency groupIds and creates targeted mappings for EOL tracking.
              """
              print("üéØ Creating dynamic EOL mappings based on found dependencies...")
              
              # Master EOL mapping rules - comprehensive database for potential matches
              eol_mapping_rules = {
                  # Spring Framework ecosystem
                  'org.springframework.boot': 'spring-boot',
                  'org.springframework': 'spring-framework',
                  'org.springframework.cloud': 'spring-cloud',
                  'org.springframework.data': 'spring-framework',
                  'org.springframework.security': 'spring-framework',
                  'org.springframework.integration': 'spring-framework',
                  'org.springframework.batch': 'spring-framework',
                  'org.springframework.webflow': 'spring-framework',
                  
                  # Jackson JSON processing
                  'com.fasterxml.jackson.core': 'jackson',
                  'com.fasterxml.jackson.dataformat': 'jackson',
                  'com.fasterxml.jackson.datatype': 'jackson',
                  'com.fasterxml.jackson.module': 'jackson',
                  'com.fasterxml.jackson.jr': 'jackson',
                  'com.fasterxml.jackson': 'jackson',
                  
                  # Database drivers and clients
                  'org.postgresql': 'postgresql',
                  'mysql': 'mysql',
                  'com.mysql': 'mysql',
                  'com.microsoft.sqlserver': 'mssql-server',
                  'com.oracle.database.jdbc': 'oracle-database',
                  'com.h2database': 'h2',
                  'org.hsqldb': 'hsqldb',
                  'org.apache.derby': 'derby',
                  'org.xerial': 'sqlite',
                  'redis.clients': 'redis',
                  'org.mongodb': 'mongodb',
                  'dev.morphia.morphia': 'mongodb',
                  'io.lettuce': 'redis',
                  'org.redisson': 'redis',
                  
                  # Web servers and networking
                  'org.apache.tomcat': 'tomcat',
                  'org.apache.tomcat.embed': 'tomcat',
                  'org.eclipse.jetty': 'jetty',
                  'io.undertow': 'undertow',
                  'io.netty': 'netty',
                  'org.apache.httpcomponents': 'apache-httpclient',
                  'org.apache.httpcomponents.client5': 'apache-httpclient',
                  'org.apache.httpcomponents.core5': 'apache-httpcore',
                  
                  # Logging frameworks
                  'ch.qos.logback': 'logback',
                  'org.slf4j': 'slf4j',
                  'org.apache.logging.log4j': 'log4j',
                  'org.jboss.logging': 'jboss',
                  'commons-logging': 'commons-logging',
                  'log4j': 'log4j',
                  
                  # Testing frameworks
                  'junit': 'junit',
                  'org.junit.jupiter': 'junit',
                  'org.junit.platform': 'junit',
                  'org.junit': 'junit',
                  'org.testng': 'testng',
                  'org.mockito': 'mockito',
                  'org.hamcrest': 'hamcrest',
                  'org.assertj': 'assertj',
                  'com.github.tomakehurst': 'wiremock',
                  'org.testcontainers': 'testcontainers',
                  'org.spockframework': 'spock',
                  
                  # Java/Jakarta EE and specifications
                  'javax.servlet': 'java-ee',
                  'javax.annotation': 'java-ee',
                  'javax.validation': 'java-ee',
                  'javax.xml.bind': 'java-ee',
                  'javax.activation': 'java-ee',
                  'jakarta.servlet': 'jakarta-ee',
                  'jakarta.annotation': 'jakarta-ee',
                  'jakarta.validation': 'jakarta-ee',
                  'jakarta.xml.bind': 'jakarta-ee',
                  'jakarta.activation': 'jakarta-ee',
                  'jakarta.persistence': 'jakarta-ee',
                  'org.eclipse.persistence': 'eclipselink',
                  
                  # API documentation and OpenAPI
                  'io.swagger.core.v3': 'openapi',
                  'io.swagger.v3': 'openapi',
                  'org.springdoc': 'openapi',
                  'org.openapi4j': 'openapi',
                  'io.swagger': 'swagger',
                  
                  # Validation and ORM
                  'org.hibernate.validator': 'hibernate',
                  'org.hibernate': 'hibernate',
                  'org.hibernate.orm': 'hibernate',
                  'org.mybatis': 'mybatis',
                  'com.querydsl': 'querydsl',
                  'org.jooq': 'jooq',
                  
                  # Reactive programming
                  'io.projectreactor': 'reactor',
                  'io.projectreactor.netty': 'reactor',
                  'io.projectreactor.addons': 'reactor',
                  'org.reactivestreams': 'reactive-streams',
                  'io.reactivex.rxjava3': 'rxjava',
                  'io.reactivex.rxjava2': 'rxjava',
                  'com.github.akarnokd': 'rxjava',
                  
                  # Metrics, monitoring and observability
                  'io.micrometer': 'micrometer',
                  'io.prometheus': 'prometheus',
                  'io.zipkin.brave': 'brave',
                  'io.jaegertracing': 'jaeger',
                  'io.opentracing': 'opentracing',
                  'io.opentelemetry': 'opentelemetry',
                  
                  # Resilience and fault tolerance
                  'io.github.resilience4j': 'resilience4j',
                  'com.netflix.hystrix': 'hystrix',
                  'com.netflix.ribbon': 'ribbon',
                  'com.netflix.eureka': 'eureka',
                  
                  # Security and cryptography
                  'org.bouncycastle': 'bouncy-castle',
                  'io.jsonwebtoken': 'jwt',
                  'com.nimbusds': 'nimbus-jose-jwt',
                  'org.springframework.security': 'spring-security',
                  'org.apache.shiro': 'shiro',
                  'org.keycloak': 'keycloak',
                  
                  # Serialization and data formats
                  'org.yaml': 'snakeyaml',
                  'com.google.code.gson': 'gson',
                  'com.jayway.jsonpath': 'jsonpath',
                  'com.fasterxml.woodstox': 'woodstox',
                  'org.apache.avro': 'avro',
                  'com.google.protobuf': 'protobuf',
                  
                  # Apache Commons and utilities
                  'org.apache.commons': 'apache-commons',
                  'commons-codec': 'apache-commons',
                  'commons-fileupload': 'apache-commons',
                  'commons-io': 'apache-commons',
                  'commons-lang': 'apache-commons',
                  'commons-lang3': 'apache-commons',
                  'commons-collections': 'apache-commons',
                  'commons-beanutils': 'apache-commons',
                  
                  # Google libraries
                  'com.google.guava': 'guava',
                  'com.google.inject': 'guice',
                  'com.google.code.findbugs': 'findbugs',
                  
                  # Code manipulation and bytecode
                  'org.aspectj': 'aspectj',
                  'net.bytebuddy': 'byte-buddy',
                  'org.javassist': 'javassist',
                  'org.ow2.asm': 'asm',
                  'cglib': 'cglib',
                  
                  # Caching libraries
                  'com.github.ben-manes.caffeine': 'caffeine',
                  'net.sf.ehcache': 'ehcache',
                  'org.ehcache': 'ehcache',
                  'com.hazelcast': 'hazelcast',
                  
                  # Build and development tools
                  'org.projectlombok': 'lombok',
                  'org.checkerframework': 'checker-framework',
                  'org.mapstruct': 'mapstruct',
                  'org.immutables': 'immutables',
                  
                  # Message brokers and messaging
                  'org.apache.kafka': 'kafka',
                  'org.apache.activemq': 'activemq',
                  'com.rabbitmq': 'rabbitmq',
                  'org.apache.qpid': 'qpid',
                  
                  # XML processing
                  'org.dom4j': 'dom4j',
                  'jdom': 'jdom',
                  'org.jdom': 'jdom',
                  'xalan': 'xalan',
                  'xerces': 'xerces'
              }
              
              # Analyze found dependencies and create targeted mappings
              eol_mappings = {}
              dependency_groups = set()
              
              print(f"  Analyzing {len(dependencies)} dependencies for EOL mapping...")
              
              for dep_key, dep_info in dependencies.items():
                  group_id = dep_info['groupId']
                  dependency_groups.add(group_id)
                  
                  # Check for exact matches first
                  if group_id in eol_mapping_rules:
                      eol_product = eol_mapping_rules[group_id]
                      eol_mappings[group_id] = eol_product
                      print(f"    ‚úÖ Direct match: {group_id} -> {eol_product}")
                      continue
                  
                  # Check for prefix matches (for sub-modules)
                  matched = False
                  for rule_prefix, eol_product in eol_mapping_rules.items():
                      if group_id.startswith(rule_prefix):
                          eol_mappings[group_id] = eol_product
                          print(f"    üì¶ Prefix match: {group_id} -> {eol_product} (via {rule_prefix})")
                          matched = True
                          break
                  
                  if not matched:
                      print(f"    ‚ùì No EOL mapping found for: {group_id}")
              
              # Summary
              unique_eol_products = set(eol_mappings.values())
              print(f"  üìä Created {len(eol_mappings)} mappings covering {len(unique_eol_products)} EOL products")
              print(f"  üéØ EOL products to track: {', '.join(sorted(unique_eol_products))}")
              
              return eol_mappings, dependency_groups
          
          # Create dynamic EOL mappings based on found dependencies
          eol_mappings, dependency_groups = create_dynamic_eol_mappings(deps)
          
          # Exclude internal project modules
          internal_prefixes = ['org.eclipse.ecsp']
          
          print(f"\nüîó Mapping {len(deps)} dependencies to EOL products...")
          
          eol_deps = {}
          mapped_count = 0
          skipped_count = 0
          
          for dep_key, dep_info in deps.items():
              group_id = dep_info['groupId']
              
              # Skip internal project modules
              is_internal = any(group_id.startswith(prefix) for prefix in internal_prefixes)
              if is_internal:
                  print(f"  ‚è≠Ô∏è  Skipping internal module: {dep_key}")
                  skipped_count += 1
                  continue
              
              # Map to EOL products using dynamic mappings
              mapped = False
              
              # First try exact match
              if group_id in eol_mappings:
                  eol_product = eol_mappings[group_id]
                  
                  # Handle multiple dependencies mapping to same EOL product
                  # Keep the one with the most specific version or latest found
                  if eol_product not in eol_deps or len(dep_info['version']) > len(eol_deps[eol_product]['version']):
                      eol_deps[eol_product] = {
                          'version': dep_info['version'],
                          'dependency': dep_key,
                          'groupId': group_id
                      }
                  
                  print(f"  ‚úÖ Exact match: {dep_key} -> {eol_product}")
                  mapped = True
                  mapped_count += 1
              else:
                  # Try prefix matching for sub-modules
                  for mapping_group, eol_product in eol_mappings.items():
                      if group_id.startswith(mapping_group):
                          
                          # Handle multiple dependencies mapping to same EOL product
                          if eol_product not in eol_deps or len(dep_info['version']) > len(eol_deps[eol_product]['version']):
                              eol_deps[eol_product] = {
                                  'version': dep_info['version'],
                                  'dependency': dep_key,
                                  'groupId': group_id
                              }
                          
                          print(f"  üì¶ Prefix match: {dep_key} -> {eol_product} (via {mapping_group})")
                          mapped = True
                          mapped_count += 1
                          break
              
              if not mapped:
                  print(f"  ‚ùì No EOL mapping: {dep_key}")
          
          print(f"\nüìä Mapping Summary:")
          print(f"  Total dependencies: {len(deps)}")
          print(f"  Internal modules skipped: {skipped_count}")
          print(f"  Dependencies mapped: {mapped_count}")
          print(f"  Unique EOL products: {len(eol_deps)}")
          
          # Save results with enhanced metadata
          eol_output = {}
          for eol_product, info in eol_deps.items():
              eol_output[eol_product] = {
                  'version': info['version'],
                  'dependency': info['dependency'],
                  'groupId': info['groupId'],
                  'mapped_at': datetime.now().isoformat()
              }
          
          with open('eol_dependencies.json', 'w') as f:
              json.dump(eol_output, f, indent=2)
          
          # Enhanced output
          if not eol_deps:
              print("\n‚ùì No dependencies mapped to trackable EOL products")
              print("   This could mean:")
              print("   - All dependencies are very new/unknown products")
              print("   - Dependencies are mostly internal modules")
              print("   - EOL mapping rules need expansion")
          else:
              print(f"\nüéØ EOL-trackable dependencies ({len(eol_deps)} unique products):")
              for eol_product, info in sorted(eol_deps.items()):
                  print(f"  üì¶ {eol_product}: {info['version']} (from {info['dependency']})")
          
          # Save dependency analysis metadata
          analysis_metadata = {
              'analysis_date': datetime.now().isoformat(),
              'total_dependencies': len(deps),
              'internal_modules_skipped': skipped_count,
              'dependencies_mapped': mapped_count,
              'unique_eol_products': len(eol_deps),
              'dependency_groups_found': sorted(list(dependency_groups)),
              'eol_mappings_used': len(eol_mappings)
          }
          
          with open('dependency_analysis.json', 'w') as f:
              json.dump(analysis_metadata, f, indent=2)
          EOF
          
    - name: Check EOL status for dependencies
      id: eol-check
      run: |
        echo "Checking EOL status using endoflife.date API..."
        
        # Set threshold days (default 90 days)
        THRESHOLD_DAYS="${{ github.event.inputs.days_threshold || '90' }}"
        
        cat > check_eol.py << 'EOF'
        import json
        import requests
        import sys
        from datetime import datetime, timedelta
        import os
        
        def check_eol_status():
            threshold_days = int(os.getenv('THRESHOLD_DAYS', '90'))
            today = datetime.now()
            threshold_date = today + timedelta(days=threshold_days)
            
            with open('eol_dependencies.json', 'r') as f:
                dependencies = json.load(f)
            
            results = {
                'eol': [],
                'approaching_eol': [],
                'supported': [],
                'unknown': []
            }
            
            for product, info in dependencies.items():
                try:
                    print(f"Checking {product}...")
                    
                    # Get product info from endoflife.date API
                    response = requests.get(f'https://endoflife.date/api/{product}.json', timeout=10)
                    
                    if response.status_code != 200:
                        print(f"  Product {product} not found in EOL database")
                        results['unknown'].append({
                            'product': product,
                            'version': info['version'],
                            'dependency': info['dependency'],
                            'reason': 'Product not found in EOL database'
                        })
                        continue
                    
                    cycles = response.json()
                    current_version = info['version']
                    
                    # Find matching version or closest version
                    matching_cycle = None
                    for cycle in cycles:
                        cycle_version = str(cycle.get('cycle', ''))
                        
                        # Direct match
                        if current_version.startswith(cycle_version):
                            matching_cycle = cycle
                            break
                        
                        # Semantic version match (e.g., 2.7.x matches 2.7)
                        if current_version.split('.')[0] == cycle_version.split('.')[0]:
                            if len(cycle_version.split('.')) >= 2 and len(current_version.split('.')) >= 2:
                                if current_version.split('.')[1] == cycle_version.split('.')[1]:
                                    matching_cycle = cycle
                                    break
                    
                    if not matching_cycle:
                        # Use the first (latest) cycle as fallback
                        matching_cycle = cycles[0] if cycles else None
                    
                    if not matching_cycle:
                        results['unknown'].append({
                            'product': product,
                            'version': current_version,
                            'dependency': info['dependency'],
                            'reason': 'No matching version cycle found'
                        })
                        continue
                    
                    eol_date = matching_cycle.get('eol')
                    support_date = matching_cycle.get('support')
                    lts = matching_cycle.get('lts', False)
                    
                    # Parse EOL date
                    eol_datetime = None
                    if eol_date and eol_date != True and eol_date != False:
                        try:
                            eol_datetime = datetime.strptime(str(eol_date), '%Y-%m-%d')
                        except:
                            pass
                    
                    # Check status
                    status_info = {
                        'product': product,
                        'version': current_version,
                        'dependency': info['dependency'],
                        'cycle': matching_cycle.get('cycle'),
                        'eol_date': eol_date,
                        'support_date': support_date,
                        'lts': lts
                    }
                    
                    if eol_date == True:
                        results['eol'].append(status_info)
                        print(f"  ‚ùå {product} {current_version} is EOL")
                    elif eol_datetime and eol_datetime <= today:
                        results['eol'].append(status_info)
                        print(f"  ‚ùå {product} {current_version} is EOL (since {eol_date})")
                    elif eol_datetime and eol_datetime <= threshold_date:
                        status_info['days_until_eol'] = (eol_datetime - today).days
                        results['approaching_eol'].append(status_info)
                        print(f"  ‚ö†Ô∏è  {product} {current_version} approaching EOL ({eol_date})")
                    else:
                        results['supported'].append(status_info)
                        print(f"  ‚úÖ {product} {current_version} is supported")
                        
                except Exception as e:
                    print(f"  Error checking {product}: {e}")
                    results['unknown'].append({
                        'product': product,
                        'version': info['version'],
                        'dependency': info['dependency'],
                        'reason': f'Error: {str(e)}'
                    })
            
            return results
        
        # Run EOL check
        results = check_eol_status()
        
        # Save results
        with open('eol_results.json', 'w') as f:
            json.dump(results, f, indent=2)
        
        # Output summary
        total_checked = len(results['eol']) + len(results['approaching_eol']) + len(results['supported']) + len(results['unknown'])
        print(f"\nüìä EOL Check Summary:")
        print(f"Total dependencies checked: {total_checked}")
        print(f"‚ùå EOL: {len(results['eol'])}")
        print(f"‚ö†Ô∏è  Approaching EOL: {len(results['approaching_eol'])}")
        print(f"‚úÖ Supported: {len(results['supported'])}")
        print(f"‚ùì Unknown: {len(results['unknown'])}")
        
        # Set outputs for GitHub Actions
        eol_count = len(results['eol'])
        approaching_count = len(results['approaching_eol'])
        
        print(f"EOL_COUNT={eol_count}")
        print(f"APPROACHING_COUNT={approaching_count}")
        print(f"TOTAL_ISSUES={eol_count + approaching_count}")
        EOF
        
        # Check if we have dependencies to analyze
        if [ -f eol_dependencies.json ] && [ -s eol_dependencies.json ]; then
          # Set environment variable and run the Python script
          THRESHOLD_DAYS="$THRESHOLD_DAYS" python3 check_eol.py
          
          # Set GitHub environment variables from Python output
          EOL_COUNT=$(python3 -c 'import json; f=open("eol_results.json"); r=json.load(f); f.close(); print(len(r["eol"]))' 2>/dev/null || echo 0)
          APPROACHING_COUNT=$(python3 -c 'import json; f=open("eol_results.json"); r=json.load(f); f.close(); print(len(r["approaching_eol"]))' 2>/dev/null || echo 0)
        else
          echo "No dependencies found to check - creating empty results"
          EOL_COUNT=0
          APPROACHING_COUNT=0
          
          # Create empty results file
          echo '{"eol":[],"approaching_eol":[],"supported":[],"unknown":[]}' > eol_results.json
        fi
        
        TOTAL_ISSUES=$((EOL_COUNT + APPROACHING_COUNT))
        
        echo "EOL_COUNT=$EOL_COUNT" >> $GITHUB_ENV
        echo "APPROACHING_COUNT=$APPROACHING_COUNT" >> $GITHUB_ENV
        echo "TOTAL_ISSUES=$TOTAL_ISSUES" >> $GITHUB_ENV
        
        # Also set step outputs for conditional logic
        echo "eol-count=$EOL_COUNT" >> $GITHUB_OUTPUT
        echo "approaching-count=$APPROACHING_COUNT" >> $GITHUB_OUTPUT
        echo "total-issues=$TOTAL_ISSUES" >> $GITHUB_OUTPUT
        
    - name: Generate EOL Report
      id: generate-report
      run: |
        echo "Generating detailed EOL report..."
        
        cat > generate_report.py << 'EOF'
        import json
        from datetime import datetime
        
        def generate_markdown_report():
            with open('eol_results.json', 'r') as f:
                results = json.load(f)
            
            report = []
            report.append("# üîç Dependencies End-of-Life Report")
            report.append(f"*Generated on {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}*")
            report.append("")
            
            # Summary
            total = len(results['eol']) + len(results['approaching_eol']) + len(results['supported']) + len(results['unknown'])
            report.append("## üìä Summary")
            report.append("| Status | Count | Description |")
            report.append("|--------|--------|-------------|")
            report.append(f"| ‚ùå EOL | {len(results['eol'])} | Dependencies that have reached end-of-life |")
            report.append(f"| ‚ö†Ô∏è Approaching EOL | {len(results['approaching_eol'])} | Dependencies approaching EOL within threshold |")
            report.append(f"| ‚úÖ Supported | {len(results['supported'])} | Dependencies with active support |")
            report.append(f"| ‚ùì Unknown | {len(results['unknown'])} | Dependencies not found in EOL database |")
            report.append(f"| **Total** | **{total}** | **All checked dependencies** |")
            report.append("")
            
            # EOL Dependencies
            if results['eol']:
                report.append("## ‚ùå End-of-Life Dependencies")
                report.append("These dependencies have reached their end-of-life and should be updated immediately:")
                report.append("")
                report.append("| Product | Version | Dependency | EOL Date | LTS |")
                report.append("|---------|---------|------------|----------|-----|")
                for dep in results['eol']:
                    lts_badge = "‚úÖ" if dep.get('lts') else "‚ùå"
                    eol_date = dep.get('eol_date', 'Unknown')
                    report.append(f"| {dep['product']} | {dep['version']} | `{dep['dependency']}` | {eol_date} | {lts_badge} |")
                report.append("")
            
            # Approaching EOL
            if results['approaching_eol']:
                report.append("## ‚ö†Ô∏è Dependencies Approaching EOL")
                report.append("These dependencies will reach end-of-life soon:")
                report.append("")
                report.append("| Product | Version | Dependency | EOL Date | Days Until EOL | LTS |")
                report.append("|---------|---------|------------|----------|----------------|-----|")
                for dep in results['approaching_eol']:
                    lts_badge = "‚úÖ" if dep.get('lts') else "‚ùå"
                    days_until = dep.get('days_until_eol', 'Unknown')
                    eol_date = dep.get('eol_date', 'Unknown')
                    report.append(f"| {dep['product']} | {dep['version']} | `{dep['dependency']}` | {eol_date} | {days_until} | {lts_badge} |")
                report.append("")
            
            # Supported Dependencies
            if results['supported']:
                report.append("## ‚úÖ Supported Dependencies")
                report.append("<details>")
                report.append("<summary>Click to expand supported dependencies</summary>")
                report.append("")
                report.append("| Product | Version | Dependency | EOL Date | LTS |")
                report.append("|---------|---------|------------|----------|-----|")
                for dep in results['supported']:
                    lts_badge = "‚úÖ" if dep.get('lts') else "‚ùå"
                    eol_date = dep.get('eol_date', 'Future')
                    report.append(f"| {dep['product']} | {dep['version']} | `{dep['dependency']}` | {eol_date} | {lts_badge} |")
                report.append("")
                report.append("</details>")
                report.append("")
            
            # Unknown Dependencies
            if results['unknown']:
                report.append("## ‚ùì Unknown Dependencies")
                report.append("These dependencies could not be checked against the EOL database:")
                report.append("")
                report.append("| Product | Version | Dependency | Reason |")
                report.append("|---------|---------|------------|--------|")
                for dep in results['unknown']:
                    reason = dep.get('reason', 'Unknown')
                    report.append(f"| {dep['product']} | {dep['version']} | `{dep['dependency']}` | {reason} |")
                report.append("")
            
            # Recommendations
            report.append("## üîß Recommendations")
            if results['eol']:
                report.append("### Immediate Action Required")
                report.append("- Update all EOL dependencies to supported versions")
                report.append("- Check for security vulnerabilities in EOL dependencies")
                report.append("- Plan migration timeline for breaking changes")
            
            if results['approaching_eol']:
                report.append("### Plan for Updates")
                report.append("- Schedule updates for dependencies approaching EOL")
                report.append("- Test compatibility with newer versions")
                report.append("- Monitor release schedules for dependency updates")
            
            report.append("")
            report.append("### Useful Resources")
            report.append("- [endoflife.date](https://endoflife.date/) - EOL information database")
            report.append("- [OWASP Dependency Check](https://owasp.org/www-project-dependency-check/) - Security vulnerability scanning")
            report.append("- [Renovate](https://renovatebot.com/) - Automated dependency updates")
            
            return "\n".join(report)
        
        # Generate report
        markdown_report = generate_markdown_report()
        
        # Save report
        with open('eol_report.md', 'w') as f:
            f.write(markdown_report)
        
        print("Report generated successfully!")
        EOF
        
        python3 generate_report.py
        
    - name: Upload EOL Report
      uses: actions/upload-artifact@v4
      with:
        name: eol-report
        path: |
          eol_report.md
          eol_results.json
          eol_dependencies.json
          dependency_analysis.json
        retention-days: 30
        
    - name: Comment on PR (if applicable)
      if: github.event_name == 'pull_request' && steps.eol-check.outputs.total-issues != '0'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const report = fs.readFileSync('eol_report.md', 'utf8');
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: `## üîç EOL Dependencies Check Results\n\n${report}`
          });
          
    - name: Create Issue for EOL Dependencies
      if: steps.eol-check.outputs.eol-count != '0' && github.event_name == 'schedule'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const report = fs.readFileSync('eol_report.md', 'utf8');
          
          // Check if EOL issue already exists
          const issues = await github.rest.issues.listForRepo({
            owner: context.repo.owner,
            repo: context.repo.repo,
            labels: ['dependencies', 'eol'],
            state: 'open'
          });
          
          const title = `üîç End-of-Life Dependencies Detected (${process.env.EOL_COUNT} EOL, ${process.env.APPROACHING_COUNT} approaching)`;
          
          if (issues.data.length === 0) {
            // Create new issue
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: title,
              body: report,
              labels: ['dependencies', 'eol', 'security']
            });
          } else {
            // Update existing issue
            await github.rest.issues.update({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issues.data[0].number,
              title: title,
              body: report
            });
          }
          
    - name: Add to GitHub Summary
      run: |
        echo "## üîç EOL Dependencies Check Results" >> $GITHUB_STEP_SUMMARY
        cat eol_report.md >> $GITHUB_STEP_SUMMARY
        
    - name: Fail on EOL Dependencies
      if: github.event.inputs.fail_on_eol == 'true' && steps.eol-check.outputs.eol-count != '0'
      run: |
        echo "‚ùå Failing workflow due to $EOL_COUNT EOL dependencies found"
        echo "Use the generated report to update these dependencies"
        exit 1
